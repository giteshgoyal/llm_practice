{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdAbYStJz6/wchs9X+t7Is",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giteshgoyal/llm_practice/blob/main/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Vocablury\n",
        "\n",
        "1. Load the text\n",
        "2. Split the text using whitespace, punctations as delimiter\n",
        "3. Remove whitespace from token list (this is optional as we may need whitepace as token)\n",
        "4. Sort and assign value to token list."
      ],
      "metadata": {
        "id": "nktWoT6q1mLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Text"
      ],
      "metadata": {
        "id": "wBomBbkb2YQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load text using url"
      ],
      "metadata": {
        "id": "9TycQdPz7jkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get(\"https://raw.githubusercontent.com/giteshgoyal/llm_practice/refs/heads/main/verdict.txt\")\n",
        "raw_text = response.text\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxIYxJNr2cEo",
        "outputId": "37c11de7-4f58-421e-890f-6df77796d98f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20480\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load using cloning the git repo"
      ],
      "metadata": {
        "id": "ymFi3ahb7-RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/giteshgoyal/llm_practice.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dZuDrTr-gzo",
        "outputId": "6823009d-d885-4844-f0ad-a5c261774165"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'llm_practice' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "with open(\"llm_practice/verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text=f.read()\n",
        "\n",
        "print(\"Total number of character: \", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSQDf8MS-urz",
        "outputId": "4005c449-d98c-4b37-d46e-6a0f5a72651f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm_practice  sample_data\n",
            "Total number of character:  20480\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the text using whitespace, punctations as delimiter"
      ],
      "metadata": {
        "id": "K0dXlpJWBg2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "splited_data=re.split(r'([,.:;?_!\"()\\']|\\s)',raw_text)\n",
        "print(splited_data[:99])\n",
        "print(len(splited_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZmBr-uoAQGc",
        "outputId": "35b6a9d7-5d55-44da-fa51-07f952e789b7"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius--though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough--so', ' ', 'it', ' ', 'was', ' ', 'no', ' ', 'great', ' ', 'surprise', ' ', 'to', ' ', 'me', ' ', 'to', ' ', 'hear', ' ', 'that', ',', '', ' ', 'in', ' ', 'the', ' ', 'height', ' ', 'of', ' ', 'his', ' ', 'glory', ',', '', ' ', 'he', ' ', 'had', ' ', 'dropped', ' ', 'his', ' ', 'painting', ',', '', ' ', 'married', ' ', 'a', ' ', 'rich', ' ', 'widow', ',', '', ' ', 'and', ' ', 'established', ' ', 'himself', ' ', 'in', ' ', 'a', ' ', 'villa', ' ', 'on']\n",
            "9043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove whitespace from token list"
      ],
      "metadata": {
        "id": "Xg2ReRr3BZCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data= [data.strip() for data in splited_data if data.split()]\n",
        "print(cleaned_data[:99])\n",
        "print(len(cleaned_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f9SSTQwBX_9",
        "outputId": "958cd07a-561f-494b-c844-a1610b890f2b"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius--though', 'a', 'good', 'fellow', 'enough--so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I', 'rather', 'thought', 'it', 'would', 'have', 'been', 'Rome', 'or', 'Florence', '.', ')', '\"', 'The', 'height', 'of', 'his', 'glory', '\"', '--that', 'was', 'what', 'the', 'women', 'called', 'it', '.', 'I', 'can', 'hear', 'Mrs', '.', 'Gideon', 'Thwing--his', 'last', 'Chicago', 'sitter--deploring', 'his', 'unaccountable', 'abdication', '.', '\"', 'Of', 'course']\n",
            "4506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sort and assign value to token list.\n"
      ],
      "metadata": {
        "id": "pasmNTpFB4Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_data= sorted(set(cleaned_data))\n",
        "print(len(sorted_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9erlNLj4B_Rs",
        "outputId": "0620919e-7e0a-46b9-db5e-2b80b18641ab"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab= {data:id for id,data in enumerate(sorted_data)}\n",
        "for w,i in vocab.items():\n",
        "  print(w,\":\",i)\n",
        "  if i >30:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUEO7h0UCeek",
        "outputId": "4d2d6351-8d6c-419f-f118-40f99f83fa1f"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "! : 0\n",
            "\" : 1\n",
            "' : 2\n",
            "( : 3\n",
            ") : 4\n",
            ", : 5\n",
            "--and : 6\n",
            "--even : 7\n",
            "--it : 8\n",
            "--oh : 9\n",
            "--she : 10\n",
            "--that : 11\n",
            ". : 12\n",
            ": : 13\n",
            "; : 14\n",
            "? : 15\n",
            "A : 16\n",
            "Ah : 17\n",
            "Ah--I : 18\n",
            "Among : 19\n",
            "And : 20\n",
            "Are : 21\n",
            "Arrt : 22\n",
            "As : 23\n",
            "At : 24\n",
            "Be : 25\n",
            "Begin : 26\n",
            "Burlington : 27\n",
            "But : 28\n",
            "By : 29\n",
            "Carlo : 30\n",
            "Chicago : 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Based Tokenizer"
      ],
      "metadata": {
        "id": "_RBGNtmkDwnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without taking care of Out of Vocab words."
      ],
      "metadata": {
        "id": "4Oq7_Y9WDV9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WordBasedTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str= {id:data for data,id in vocab.items()}\n",
        "\n",
        "  # 1. Split text into words\n",
        "  # 2. Replace words with ids using vocab\n",
        "\n",
        "  def encoder(self, text):\n",
        "    splited_data=re.split(r'([,.:;?_!\"()\\']|\\s)', text)\n",
        "    cleaned_data= [data.strip() for data in splited_data if data.split()]\n",
        "    token_id= [self.str_to_int[word] for word in cleaned_data]\n",
        "    return token_id\n",
        "\n",
        "  def decoder(self, token_ids):\n",
        "    words=[self.int_to_str[id] for id in token_ids]\n",
        "    sentence=\" \".join(words)\n",
        "    clean_sentence=re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', sentence)\n",
        "    return clean_sentence\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2G1oTmclDiiK"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= WordBasedTokenizerV1(vocab)"
      ],
      "metadata": {
        "id": "ry-E-53mHzBM"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"\"It's the last he painted, you know,\"\n",
        "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids=tokenizer.encoder(text1)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z6bkiJ9Hqq5",
        "outputId": "2a48ea27-a965-43c3-a956-dd447d2822ea"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 64, 2, 910, 1053, 640, 559, 799, 5, 1195, 634, 5, 1, 77, 12, 44, 911, 1177, 809, 853, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decoder(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DZ-4_G_hJA9c",
        "outputId": "a751a0eb-a872-4994-80aa-d5f402dafb97"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Out of Box Word Gives KeyError"
      ],
      "metadata": {
        "id": "NlGWfZt-IMrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"The court hereby finds the defendant guilty beyond reasonable doubt. Objection overruled,judgment delivered. Counsel presented compelling evidence.\n",
        "The jury, unanimous in its verdict, adjourned. Amidst the legal jargon stood silence, coffee, echo, remorse, precedent, and truth.\n",
        "Signed, sealed, recorded — justice prevailed in a chamber echoing law and humanity.\"\"\"\n",
        "ids1=tokenizer.encoder(text)\n",
        "print(ids1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "HMvnRCvxFzv6",
        "outputId": "2fd9c232-c110-48d3-b577-c6cac3664942"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'court'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-2173206481>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mjury\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munanimous\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mits\u001b[0m \u001b[0mverdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjourned\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAmidst\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlegal\u001b[0m \u001b[0mjargon\u001b[0m \u001b[0mstood\u001b[0m \u001b[0msilence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoffee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mecho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremorse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecedent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m Signed, sealed, recorded — justice prevailed in a chamber echoing law and humanity.\"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mids1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-150-33598197>\u001b[0m in \u001b[0;36mencoder\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msplited_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([,.:;?_!\"()\\']|\\s)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcleaned_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplited_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtoken_id\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-150-33598197>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msplited_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([,.:;?_!\"()\\']|\\s)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcleaned_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplited_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtoken_id\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'court'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Out of Box Words with SPECIAL CONTEXT TOKENS\n",
        "\n",
        "1. Include SPECIAL CONTEXT TOKENS like \"<|endoftext|>\", \"<|unk|>\"\n",
        "2. Modify Encoder to handle Out of Box Words"
      ],
      "metadata": {
        "id": "vUaJpCtnJZ_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_data= sorted(set(cleaned_data))\n",
        "sorted_data.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "print(len(sorted_data))\n",
        "\n",
        "vocab= {data:id for id,data in enumerate(sorted_data)}\n",
        "for w,i in vocab.items():\n",
        "  if i < 1190:\n",
        "    continue\n",
        "  print(w,\":\",i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLVjz5ohJZJa",
        "outputId": "e00a88dd-ad5d-4b96-e827-50d8e95965b5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1202\n",
            "wouldn : 1190\n",
            "year : 1191\n",
            "years : 1192\n",
            "yellow : 1193\n",
            "yet : 1194\n",
            "you : 1195\n",
            "you--because : 1196\n",
            "younger : 1197\n",
            "your : 1198\n",
            "yourself : 1199\n",
            "<|endoftext|> : 1200\n",
            "<|unk|> : 1201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WordBasedTokenizerV2:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int=vocab\n",
        "    self.int_to_str= {id:data for data,id in vocab.items()}\n",
        "\n",
        "  # 1. Split text into words\n",
        "  # 2. Replace words with ids using vocab\n",
        "\n",
        "  def encoder(self, text):\n",
        "    splited_data=re.split(r'([,.:;?_!\"()\\']|\\s)', text)\n",
        "    cleaned_data= [data.strip() for data in splited_data if data.split()]\n",
        "    token_id= [self.str_to_int[word] if word in self.str_to_int else self.str_to_int[\"<|unk|>\"] for word in cleaned_data]\n",
        "    return token_id\n",
        "\n",
        "  def decoder(self, token_ids):\n",
        "    words=[self.int_to_str[id] for id in token_ids]\n",
        "    sentence=\" \".join(words)\n",
        "    clean_sentence=re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', sentence)\n",
        "    return clean_sentence\n"
      ],
      "metadata": {
        "id": "7acWU7SWLHOS"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizerV2= WordBasedTokenizerV2(vocab)"
      ],
      "metadata": {
        "id": "kCqS0_6dM9Ue"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text1, end=\"\\n\\n\")\n",
        "ids2=tokenizerV2.encoder(text1)\n",
        "print(ids2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ4ga8_pLST2",
        "outputId": "39c93beb-38d6-4510-83d8-4c57e1d771c9"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"It's the last he painted, you know,\" \n",
            "           Mrs. Gisburn said with pardonable pride.\n",
            "\n",
            "[1, 64, 2, 910, 1053, 640, 559, 799, 5, 1195, 634, 5, 1, 77, 12, 44, 911, 1177, 809, 853, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decoder(ids2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FD3ZH6nNwgb",
        "outputId": "df558b79-88bf-4260-9871-c0495c2d61d3"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text, end=\"\\n\\n\")\n",
        "ids3=tokenizerV2.encoder(text)\n",
        "print(ids3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVzJxNDGLWbo",
        "outputId": "7139e7b5-cb35-4a1c-b2b3-f76408f54e84"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The court hereby finds the defendant guilty beyond reasonable doubt. Objection overruled,judgment delivered. Counsel presented compelling evidence. \n",
            "The jury, unanimous in its verdict, adjourned. Amidst the legal jargon stood silence, coffee, echo, remorse, precedent, and truth.\n",
            "Signed, sealed, recorded — justice prevailed in a chamber echoing law and humanity.\n",
            "\n",
            "[106, 1201, 1201, 1201, 1053, 1201, 1201, 1201, 1201, 1201, 12, 1201, 1201, 5, 1201, 1201, 12, 1201, 1201, 1201, 1201, 12, 106, 1201, 5, 1201, 601, 624, 1201, 5, 1201, 12, 1201, 1053, 1201, 1201, 990, 1201, 5, 1201, 5, 1201, 5, 1201, 5, 1201, 5, 177, 1103, 12, 1201, 5, 1201, 5, 1201, 1201, 1201, 1201, 601, 134, 1201, 1201, 1201, 177, 1201, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizerV2.decoder(ids3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL4fkbOwOGx6",
        "outputId": "68301599-3308-41cb-a8cf-0751b6cad034"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The <|unk|> <|unk|> <|unk|> the <|unk|> <|unk|> <|unk|> <|unk|> <|unk|>. <|unk|> <|unk|>, <|unk|> <|unk|>. <|unk|> <|unk|> <|unk|> <|unk|>. The <|unk|>, <|unk|> in its <|unk|>, <|unk|>. <|unk|> the <|unk|> <|unk|> stood <|unk|>, <|unk|>, <|unk|>, <|unk|>, <|unk|>, and truth. <|unk|>, <|unk|>, <|unk|> <|unk|> <|unk|> <|unk|> in a <|unk|> <|unk|> <|unk|> and <|unk|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmGuHTKpP9mH"
      },
      "source": [
        "### BYTE PAIR ENCODING\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiAO-mr4PowX",
        "outputId": "152d18d4-7a20-4782-e86d-a56ed5051b5d"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWqj3G_wQEPq",
        "outputId": "72237040-304c-4fc9-d470-5ee2f1035f15"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "byte_tokenizer= tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "Dn-zUIfOQJEw"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text, end=\"\\n\\n\")\n",
        "ids4= byte_tokenizer.encode(text)\n",
        "print(ids4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-6lvipeQiFg",
        "outputId": "a0989082-b456-4d66-8e04-7fe88789020e"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The court hereby finds the defendant guilty beyond reasonable doubt. Objection overruled,judgment delivered. Counsel presented compelling evidence. \n",
            "The jury, unanimous in its verdict, adjourned. Amidst the legal jargon stood silence, coffee, echo, remorse, precedent, and truth.\n",
            "Signed, sealed, recorded — justice prevailed in a chamber echoing law and humanity.\n",
            "\n",
            "[464, 2184, 29376, 7228, 262, 11304, 6717, 3675, 6397, 4719, 13, 9515, 295, 23170, 6309, 11, 10456, 5154, 6793, 13, 21023, 5545, 13206, 2370, 13, 220, 198, 464, 9002, 11, 28085, 287, 663, 15593, 11, 46055, 276, 13, 41816, 301, 262, 2742, 46468, 6204, 9550, 11, 6891, 11, 9809, 11, 34081, 11, 19719, 11, 290, 3872, 13, 198, 50, 3916, 11, 15283, 11, 6264, 851, 5316, 34429, 287, 257, 11847, 39915, 1099, 290, 9265, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "byte_tokenizer.decode(ids4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-EhxpQ7mQs9F",
        "outputId": "dac0356a-bf3d-4cd0-c0e5-9abdbe7928dd"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The court hereby finds the defendant guilty beyond reasonable doubt. Objection overruled,judgment delivered. Counsel presented compelling evidence. \\nThe jury, unanimous in its verdict, adjourned. Amidst the legal jargon stood silence, coffee, echo, remorse, precedent, and truth.\\nSigned, sealed, recorded — justice prevailed in a chamber echoing law and humanity.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    }
  ]
}